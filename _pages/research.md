---
layout: archive
title: ""
permalink: /research/
author_profile: true
---
{% include base_path %}


Diffusion Language Model Inference with Monte Carlo Tree Search
======
* __Zheng Huang__, Kiran Ramnath, Yueyan Chen, Aosong Feng, Sangmin Woo, Balasubramaniam Srinivasan, Zhichao Xu, Kang Zhou, Shuai Wang, Haibo Ding, Lin Lee Cheong
* Under Review [[Arxiv]](https://arxiv.org/abs/2512.12168)

 * Investigated reasoning and uncertainty estimation in diffusion large language models (DLMs)
 * Developed a novel MCTS framework based on token-level uncertainty to optimize DLMs initialization
 * Designed a task-splitting strategy to decompose complex problems into subtasks and guide DLM generation
 * Conducted in-depth studies on post-training, probabilistic sampling, and reasoning in diffusion language models  


Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI
========
* __Zheng Huang__, Enpei Zhang, Yinghao Cai, Weikang Qiu, Carl Yang, Elynn Chen, Xiang Zhang, Rex Ying, Dawei Zhou, Yujun Yan
* Under Review [[Arxiv]](https://arxiv.org/abs/2510.16196)
 * Proposed **PRISM**, a structured text–based fMRI decoding framework that leverages language models as a brain-aligned intermediate representation for diffusion image reconstruction
 * Introduced object-centric diffusion and automatic attribute–relationship prompt optimization to enable compositional, spatially grounded image generation
 * Validated the framework through comprehensive experiments and ablations, demonstrating state-of-the-art reconstruction quality and semantic fidelity across multiple benchmarks
 * Conducted systematic analyses of diffusion models and supervised fine-tuning for large language models 





Enhancing Size Generalization in GNNs through Disentangled Representation Learning
======
* __Zheng Huang__, Qihui Yang, Dawei Zhou and Yujun Yan
* International Conference on Machine Learning (ICML 2024) [[Arxiv]](https://arxiv.org/abs/2406.04601)


  * Researched the generalization of Graph Neural Networks (GNNs) through disentangled representation learning  
  * Proposed a novel and model-agnostic framework designed to disentangle size factors from graph representations
  * Employed size- and task-invariant augmentations, introducing a decoupling loss to minimize shared information in hidden representations
  * Conducted in-depth research on OOD generalization, explainable GNN models and disentangled representation learning


Empowering Next POI Recommendation with Multi-Relational Modeling   
======
* __Zheng Huang__, Jing Ma, Natasha Zhang Foutz and Jundong Li
* Special Interest Group on Information Retrieval (SIGIR 2022) [[Arxiv]](https://arxiv.org/abs/2204.12288)


  *  Studied on Points of Interests (POI) recommendation by capturing the influence of multiple relations
  *  Utilized multiple Graph Convolutional Networks (GCNs) with Self-Attention mechanism to capture multiple user-user social relations (family or colleague) and user-location check-in relations
  *  Adopted coupled Recurrent Neural Networks (RNNs) to capture the mutual influence between users and POIs over time
  *  Conducted in-depth research on recommender system, sequential recommendation and Graph Convolutional Networks



Assessing the Causal Impact of COVID-19 Related Policies on Outbreak Dynamics
======
* Jing Ma, Yushun Dong, __Zheng Huang__, Daniel Mietchen and Jundong Li
* International Conference on World Wide Web (WWW 2022) [[Arxiv]](https://arxiv.org/pdf/2106.01315.pdf)


  *  Studied on the causal effect of different policies in reducing the spread of COVID-19 in the US
  *  Worked on a team and developed a neural network framework (GCNs&RNNs) based on time-varying observation data to control the influence of confounders, and integrated data from different data sources
  *  Investigated the problem of causal inference and COVID-19 observational social network data  






